{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy import text # to be able to pass string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172968 entries, 0 to 172967\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype              \n",
      "---  ------             --------------   -----              \n",
      " 0   product_type_no    172968 non-null  int64              \n",
      " 1   product_type_name  172968 non-null  object             \n",
      " 2   colour_group_code  172968 non-null  int64              \n",
      " 3   colour_group_name  172968 non-null  object             \n",
      " 4   week               172968 non-null  datetime64[ns, UTC]\n",
      " 5   average_price      172968 non-null  float64            \n",
      " 6   total_units_sold   172968 non-null  int64              \n",
      " 7   unique_customers   172968 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(4), object(2)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "config = dotenv_values()\n",
    "\n",
    "# define variables for the login\n",
    "pg_user = config['POSTGRES_USER']  # align the key label with your .env file !\n",
    "pg_host = config['POSTGRES_HOST']\n",
    "pg_port = config['POSTGRES_PORT']\n",
    "pg_db = config['POSTGRES_DB']\n",
    "pg_schema = config['POSTGRES_SCHEMA']\n",
    "pg_pass = config['POSTGRES_PASS']\n",
    "\n",
    "\n",
    "url = f'postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}'\n",
    "\n",
    "engine = create_engine(url, echo=False)\n",
    "my_schema = 'capstone_barstov_industries'\n",
    "\n",
    "with engine.begin() as conn: \n",
    "    result = conn.execute(text(f'SET search_path TO {my_schema};'))\n",
    "\n",
    "with engine.begin() as conn: \n",
    "    result = conn.execute(text(f'''\n",
    "                               SELECT * FROM model_data_week; \n",
    "                                '''))\n",
    "    data = result.all()\n",
    "\n",
    "### Let's create a dataframe out of that\n",
    "model_data_week = pd.DataFrame(data) \n",
    "model_data_week.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Date Range: 2018-09-16 22:00:00 to 2020-08-23 22:00:00\n",
      "Validation Date Range: 2020-08-30 22:00:00 to 2020-09-06 22:00:00\n",
      "Test Date Range: 2020-09-13 22:00:00 to 2020-09-20 22:00:00\n",
      "Ensemble with Random Forest as Final Model - MAE: 29.640685494538445\n",
      "Ensemble with Random Forest as Final Model - RMSE: 100.83484946249463\n",
      "Feature importances from the final meta-model: [0.91164921 0.03971616 0.04863464]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inventory Sales Prediction with Ensemble Modeling\n",
    "# -------------------------------------------------\n",
    "# This notebook demonstrates the use of an ensemble model with Random Forest as the final estimator\n",
    "# to predict weekly sales for inventory management.\n",
    "\n",
    "# Imports\n",
    "# -------\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load and Preprocess Data\n",
    "# ------------------------\n",
    "# Ensure 'week' is a datetime object and remove timezone information\n",
    "data['week'] = pd.to_datetime(data['week']).dt.tz_localize(None)\n",
    "\n",
    "# Sort data by date to ensure temporal order\n",
    "data = data.sort_values(by='week')\n",
    "\n",
    "# Feature Engineering: Creating Lagged Features for Sales\n",
    "data['lag_units_sold_1week'] = data.groupby('product_type_no')['total_units_sold'].shift(1)\n",
    "data['lag_units_sold_2weeks'] = data.groupby('product_type_no')['total_units_sold'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values created by lagging (occurs at the beginning of each product group)\n",
    "data = data.dropna(subset=['lag_units_sold_1week', 'lag_units_sold_2weeks']).reset_index(drop=True)\n",
    "\n",
    "# Adding Cyclic Encoding for Weeks\n",
    "data['week_of_year'] = data['week'].dt.isocalendar().week\n",
    "data['week_sin'] = np.sin(2 * np.pi * data['week_of_year'] / 52)\n",
    "data['week_cos'] = np.cos(2 * np.pi * data['week_of_year'] / 52)\n",
    "\n",
    "# Train-Validation-Test Split with Date Ranges\n",
    "# --------------------------------------------\n",
    "\n",
    "# Define the end date as the maximum date in the dataset\n",
    "end_date = data['week'].max()\n",
    "\n",
    "# Define date ranges for train, validation, and test\n",
    "train_end_date = end_date - pd.Timedelta(weeks=4)  # End training 4 weeks before the end date\n",
    "validation_start_date = train_end_date + pd.Timedelta(weeks=2)  # Start validation 2 weeks after training ends\n",
    "validation_end_date = end_date - pd.Timedelta(weeks=2)  # End validation 2 weeks before the last date\n",
    "\n",
    "# Split data into train, validation, and test sets based on specific date ranges\n",
    "train_data = data[data['week'] <= train_end_date]\n",
    "validation_set = data[(data['week'] > train_end_date) & (data['week'] <= validation_end_date)]\n",
    "test_set = data[data['week'] > validation_end_date]\n",
    "\n",
    "# Define features and target variable\n",
    "feature_columns = ['product_type_no', 'colour_group_code', 'average_price', \n",
    "                   'lag_units_sold_1week', 'lag_units_sold_2weeks', 'week_sin', 'week_cos']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['total_units_sold']\n",
    "\n",
    "X_validation = validation_set[feature_columns]\n",
    "y_validation = validation_set['total_units_sold']\n",
    "\n",
    "X_test = test_set[feature_columns]\n",
    "y_test = test_set['total_units_sold']\n",
    "\n",
    "# Confirm the split date ranges\n",
    "print(\"Training Date Range:\", train_data['week'].min(), \"to\", train_data['week'].max())\n",
    "print(\"Validation Date Range:\", validation_set['week'].min(), \"to\", validation_set['week'].max())\n",
    "print(\"Test Date Range:\", test_set['week'].min(), \"to\", test_set['week'].max())\n",
    "\n",
    "# Initialize and Train Base Models\n",
    "# -------------------------------\n",
    "model_rf = RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)\n",
    "model_lr = LinearRegression()\n",
    "model_mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Fit each base model on the training data\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_lr.fit(X_train, y_train)\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for the validation set from each model\n",
    "preds_rf = model_rf.predict(X_validation)\n",
    "preds_lr = model_lr.predict(X_validation)\n",
    "preds_mlp = model_mlp.predict(X_validation)\n",
    "\n",
    "# Create a new DataFrame to hold the base model predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'RandomForest': preds_rf,\n",
    "    'LinearRegression': preds_lr,\n",
    "    'MLPRegressor': preds_mlp\n",
    "})\n",
    "\n",
    "# Final Meta-Model Using Random Forest\n",
    "# ------------------------------------\n",
    "final_model_rf = RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)\n",
    "final_model_rf.fit(predictions_df, y_validation)\n",
    "\n",
    "# Final Predictions and Evaluation\n",
    "# --------------------------------\n",
    "final_preds_rf = final_model_rf.predict(predictions_df)\n",
    "\n",
    "# Evaluate the Random Forest final model on validation set\n",
    "mae_rf = mean_absolute_error(y_validation, final_preds_rf)\n",
    "rmse_rf = mean_squared_error(y_validation, final_preds_rf, squared=False)\n",
    "\n",
    "print(\"Ensemble with Random Forest as Final Model - MAE:\", mae_rf)\n",
    "print(\"Ensemble with Random Forest as Final Model - RMSE:\", rmse_rf)\n",
    "\n",
    "# Feature Importance Analysis (for the final model)\n",
    "# -------------------------------------------------\n",
    "print(\"Feature importances from the final meta-model:\", final_model_rf.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average units sold per week: 270376.61320754717\n"
     ]
    }
   ],
   "source": [
    "# Group by 'week' and calculate the total units sold per week\n",
    "weekly_sales = data.groupby('week')['total_units_sold'].sum()\n",
    "\n",
    "# Calculate the average units sold per week across all weeks\n",
    "average_units_sold_per_week = weekly_sales.mean()\n",
    "\n",
    "# Display the result\n",
    "print(\"Average units sold per week:\", average_units_sold_per_week)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
