{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling and Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Machine Learning Models and Evaluation Metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Visualization (Optional, if you'd like to visualize predictions or residuals)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172977 entries, 0 to 172976\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   product_type_no    172977 non-null  int64  \n",
      " 1   product_type_name  172977 non-null  object \n",
      " 2   colour_group_code  172977 non-null  int64  \n",
      " 3   colour_group_name  172977 non-null  object \n",
      " 4   week               172977 non-null  object \n",
      " 5   average_price      172977 non-null  float64\n",
      " 6   total_units_sold   172977 non-null  int64  \n",
      " 7   unique_customers   172977 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "config = dotenv_values()\n",
    "\n",
    "# Define variables for the login\n",
    "pg_user = config['POSTGRES_USER']\n",
    "pg_host = config['POSTGRES_HOST']\n",
    "pg_port = config['POSTGRES_PORT']\n",
    "pg_db = config['POSTGRES_DB']\n",
    "pg_schema = config['POSTGRES_SCHEMA']\n",
    "pg_pass = config['POSTGRES_PASS']\n",
    "\n",
    "# Set up the PostgreSQL connection URL\n",
    "url = f'postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}'\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(url, echo=False)\n",
    "my_schema = 'capstone_barstov_industries'\n",
    "\n",
    "# Load data directly into a DataFrame\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'SET search_path TO {my_schema};'))\n",
    "    data = pd.read_sql(\"SELECT * FROM model_data_week;\", conn)\n",
    "\n",
    "# Check the DataFrame structure\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (83854, 12)\n",
      "Validation set size: (6353, 12)\n",
      "Test set size: (6594, 12)\n",
      "Extended Validation MAE: 9.357783724224776\n",
      "Extended Validation RMSE: 26.614367756322643\n",
      "Test MAE: 23.652562936002425\n",
      "Test RMSE: 75.53436267954416\n",
      "\n",
      "Predicted Inventory Needs (Test Period):\n",
      "      product_type_no  colour_group_code  predicted_inventory_needs\n",
      "0                  -1                  6                        291\n",
      "1                  -1                  7                        173\n",
      "2                  -1                  9                       1831\n",
      "3                  -1                 10                        498\n",
      "4                  -1                 12                        150\n",
      "...               ...                ...                        ...\n",
      "1914              515                 12                          2\n",
      "1915              525                  3                          3\n",
      "1916              529                 31                         96\n",
      "1917              529                 52                        108\n",
      "1918              532                  9                        163\n",
      "\n",
      "[1919 rows x 3 columns]\n",
      "\n",
      "Potential Rebalance Needs (Dynamic Low Demand Thresholds):\n",
      "     product_type_no  colour_group_code  predicted_inventory_needs  \\\n",
      "0                 -1                 42                          1   \n",
      "1                 57                  4                          4   \n",
      "2                 57                 12                         10   \n",
      "3                 57                 17                         32   \n",
      "4                 57                 19                         13   \n",
      "..               ...                ...                        ...   \n",
      "799              496                 12                          3   \n",
      "800              504                 10                          2   \n",
      "801              512                  7                          3   \n",
      "802              514                  9                          3   \n",
      "803              515                 12                          2   \n",
      "\n",
      "     rebalance_units  \n",
      "0                  1  \n",
      "1                  4  \n",
      "2                 10  \n",
      "3                 32  \n",
      "4                 13  \n",
      "..               ...  \n",
      "799                3  \n",
      "800                2  \n",
      "801                3  \n",
      "802                3  \n",
      "803                2  \n",
      "\n",
      "[804 rows x 4 columns]\n",
      "Total Predicted Inventory Needs (Test Period): 881262\n",
      "Total Rebalance Needs (Low Demand Adjustments): 25806\n",
      "Total Actual Units Sold (Test Period): 875271\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Ensure 'week' is in datetime format without timezone\n",
    "data['week'] = pd.to_datetime(data['week']).dt.tz_localize(None)\n",
    "\n",
    "# Filter data up to March 2020 and sort\n",
    "data = data[data['week'] <= \"2020-03-01\"].copy()\n",
    "data = data.sort_values(by=['product_type_no', 'colour_group_code', 'week'])\n",
    "\n",
    "# Step 1: Data-Driven Peak Season Identification Using Quantile-Based Thresholds\n",
    "\n",
    "# Calculate 90th percentile threshold for peak season within each product-type and color group\n",
    "demand_clusters = data.groupby(['product_type_no', 'colour_group_code', 'week'])['total_units_sold'].sum().reset_index()\n",
    "demand_clusters['peak_threshold'] = demand_clusters.groupby(['product_type_no', 'colour_group_code'])['total_units_sold'].transform(lambda x: x.quantile(0.90))\n",
    "\n",
    "# Flag as peak season if total_units_sold exceeds the 90th percentile threshold\n",
    "demand_clusters['is_peak_season'] = demand_clusters['total_units_sold'] >= demand_clusters['peak_threshold']\n",
    "\n",
    "# Merge peak season flags back into main dataset\n",
    "data = pd.merge(data, demand_clusters[['product_type_no', 'colour_group_code', 'week', 'is_peak_season']], \n",
    "                on=['product_type_no', 'colour_group_code', 'week'], how='left')\n",
    "\n",
    "# Remove duplicate columns if any\n",
    "if 'is_peak_season_x' in data.columns and 'is_peak_season_y' in data.columns:\n",
    "    data = data.drop(columns=['is_peak_season_x']).rename(columns={'is_peak_season_y': 'is_peak_season'})\n",
    "\n",
    "# Step 2: Feature Engineering - Lagged Features and Seasonal Features\n",
    "\n",
    "data['lag_units_sold_1week'] = data.groupby(['product_type_no', 'colour_group_code'])['total_units_sold'].shift(1)\n",
    "data['lag_units_sold_2weeks'] = data.groupby(['product_type_no', 'colour_group_code'])['total_units_sold'].shift(2)\n",
    "data = data.dropna(subset=['lag_units_sold_1week', 'lag_units_sold_2weeks']).reset_index(drop=True)\n",
    "\n",
    "# Month feature for seasonality\n",
    "data['month'] = data['week'].dt.month\n",
    "\n",
    "# Scale the price\n",
    "data['average_price'] = data['average_price'] * 10\n",
    "\n",
    "\n",
    "# Reapply the train, validation, and test splits\n",
    "train_data = data[(data['week'] >= \"2019-01-01\") & (data['week'] < \"2020-01-01\")]\n",
    "validation_data = data[(data['week'] >= \"2020-01-01\") & (data['week'] < \"2020-02-01\")]\n",
    "test_data = data[(data['week'] >= \"2020-02-01\") & (data['week'] < \"2020-03-01\")]\n",
    "\n",
    "# Print sizes for verification\n",
    "print(\"Training set size:\", train_data.shape)\n",
    "print(\"Validation set size:\", validation_data.shape)\n",
    "print(\"Test set size:\", test_data.shape)\n",
    "\n",
    "\n",
    "# Step 4: Include `is_peak_season` in the features and proceed with model training\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'product_type_no', 'colour_group_code', 'average_price',\n",
    "    'lag_units_sold_1week', 'lag_units_sold_2weeks', 'month', 'is_peak_season'\n",
    "]\n",
    "\n",
    "X_train, y_train = train_data[feature_columns], train_data['total_units_sold']\n",
    "X_validation, y_validation = validation_data[feature_columns], validation_data['total_units_sold']\n",
    "X_test, y_test = test_data[feature_columns], test_data['total_units_sold']\n",
    "\n",
    "# Initialize and train base models\n",
    "model_rf = RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)\n",
    "model_lr = LinearRegression()\n",
    "model_mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_lr.fit(X_train, y_train)\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions and round to integers\n",
    "preds_rf_val = np.round(model_rf.predict(X_validation)).astype(int)\n",
    "preds_lr_val = np.round(model_lr.predict(X_validation)).astype(int)\n",
    "preds_mlp_val = np.round(model_mlp.predict(X_validation)).astype(int)\n",
    "\n",
    "preds_rf_test = np.round(model_rf.predict(X_test)).astype(int)\n",
    "preds_lr_test = np.round(model_lr.predict(X_test)).astype(int)\n",
    "preds_mlp_test = np.round(model_mlp.predict(X_test)).astype(int)\n",
    "\n",
    "# Meta-model predictions\n",
    "val_predictions_df = pd.DataFrame({'RandomForest': preds_rf_val, 'LinearRegression': preds_lr_val, 'MLPRegressor': preds_mlp_val})\n",
    "test_predictions_df = pd.DataFrame({'RandomForest': preds_rf_test, 'LinearRegression': preds_lr_test, 'MLPRegressor': preds_mlp_test})\n",
    "\n",
    "final_model_rf = RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)\n",
    "final_model_rf.fit(val_predictions_df, y_validation)\n",
    "\n",
    "# Generate and round meta-model predictions\n",
    "final_preds_val = np.round(final_model_rf.predict(val_predictions_df)).astype(int)\n",
    "final_preds_test = np.round(final_model_rf.predict(test_predictions_df)).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_val = mean_absolute_error(y_validation, final_preds_val)\n",
    "rmse_val = mean_squared_error(y_validation, final_preds_val, squared=False)\n",
    "mae_test = mean_absolute_error(y_test, final_preds_test)\n",
    "rmse_test = mean_squared_error(y_test, final_preds_test, squared=False)\n",
    "\n",
    "print(\"Extended Validation MAE:\", mae_val)\n",
    "print(\"Extended Validation RMSE:\", rmse_val)\n",
    "print(\"Test MAE:\", mae_test)\n",
    "print(\"Test RMSE:\", rmse_test)\n",
    "\n",
    "# Aggregate inventory needs by product type and color for the test period\n",
    "test_data['predicted_inventory_needs'] = final_preds_test\n",
    "inventory_needs = test_data.groupby(['product_type_no', 'colour_group_code'])['predicted_inventory_needs'].sum().reset_index()\n",
    "\n",
    "# Calculate average demand for each product-type and color combination\n",
    "avg_demand = data.groupby(['product_type_no', 'colour_group_code'])['total_units_sold'].mean().reset_index()\n",
    "avg_demand = avg_demand.rename(columns={'total_units_sold': 'avg_demand'})\n",
    "\n",
    "# Merge average demand back into `test_data`\n",
    "test_data = pd.merge(test_data, avg_demand, on=['product_type_no', 'colour_group_code'], how='left')\n",
    "# Define multipliers for peak and non-peak seasons\n",
    "# Prioritize rebalancing non-peak season items by setting a stricter (lower) threshold\n",
    "non_peak_season_multiplier = 0.5  # Trigger rebalancing sooner for non-peak items (50% of average demand)\n",
    "peak_season_multiplier = 1.0      # Allow peak items more space (100% of average demand)\n",
    "\n",
    "# Calculate the low-demand threshold dynamically based on the seasonality of each item\n",
    "test_data['low_demand_threshold'] = np.where(\n",
    "    test_data['is_peak_season'],\n",
    "    test_data['avg_demand'] * peak_season_multiplier,     # Use peak multiplier for peak season items\n",
    "    test_data['avg_demand'] * non_peak_season_multiplier  # Use non-peak multiplier for non-peak items\n",
    ")\n",
    "\n",
    "# Calculate a rolling 4-week sum of predicted inventory needs to identify low-demand periods\n",
    "test_data['low_demand_4weeks'] = test_data.groupby(['product_type_no', 'colour_group_code'])['predicted_inventory_needs'] \\\n",
    "    .transform(lambda x: x.rolling(window=4, min_periods=1).sum())\n",
    "\n",
    "# Flag items for rebalancing based on the dynamic low-demand threshold\n",
    "test_data['rebalance_flag'] = test_data['low_demand_4weeks'] <= test_data['low_demand_threshold']\n",
    "\n",
    "# Summarize the flagged items for rebalancing\n",
    "rebalance_needs = test_data[test_data['rebalance_flag']].groupby(['product_type_no', 'colour_group_code'])['predicted_inventory_needs'].sum().reset_index()\n",
    "rebalance_needs['rebalance_units'] = np.round(rebalance_needs['predicted_inventory_needs']).astype(int)\n",
    "\n",
    "# Summarize the overall predicted inventory needs\n",
    "inventory_needs = test_data.groupby(['product_type_no', 'colour_group_code'])['predicted_inventory_needs'].sum().reset_index()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPredicted Inventory Needs (Test Period):\")\n",
    "print(inventory_needs)\n",
    "\n",
    "print(\"\\nPotential Rebalance Needs (Dynamic Low Demand Thresholds):\")\n",
    "print(rebalance_needs)\n",
    "\n",
    "print(\"Total Predicted Inventory Needs (Test Period):\", int(inventory_needs['predicted_inventory_needs'].sum()))\n",
    "print(\"Total Rebalance Needs (Low Demand Adjustments):\", int(rebalance_needs['rebalance_units'].sum()))\n",
    "print(\"Total Actual Units Sold (Test Period):\", int(y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         week  total_units_sold  low_demand_4weeks\n",
      "3  2020-02-24                76                 76\n",
      "7  2020-02-24                59                 59\n",
      "11 2020-02-24               451                451\n",
      "15 2020-02-24               100                100\n",
      "19 2020-02-24                68                 68\n"
     ]
    }
   ],
   "source": [
    "# Ensure last_week_data represents the last week in the test_data\n",
    "last_week_data = test_data[test_data['week'] == test_data['week'].max()].copy()\n",
    "\n",
    "# Validate total_units_sold exists and contains no missing values\n",
    "if 'total_units_sold' not in last_week_data.columns:\n",
    "    raise KeyError(\"The column 'total_units_sold' is missing in last_week_data.\")\n",
    "\n",
    "# Handle missing values in total_units_sold, if any\n",
    "last_week_data['total_units_sold'] = last_week_data['total_units_sold'].fillna(0)\n",
    "\n",
    "# Initialize the rolling window column\n",
    "last_week_data['low_demand_4weeks'] = last_week_data['total_units_sold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Future Predictions with Rebalance Flags for 4 Weeks Out:\n",
      "      product_type_no product_type_name  colour_group_code colour_group_name  \\\n",
      "0                  -1           Unknown                  6        Light Grey   \n",
      "1                  -1           Unknown                  7              Grey   \n",
      "2                  -1           Unknown                  9             Black   \n",
      "3                  -1           Unknown                 10             White   \n",
      "4                  -1           Unknown                 12       Light Beige   \n",
      "...               ...               ...                ...               ...   \n",
      "6563              515         Straw hat                 11         Off White   \n",
      "6564              525          Keychain                  3            Silver   \n",
      "6565              529       Mobile case                 31      Light Orange   \n",
      "6566              529       Mobile case                 52              Pink   \n",
      "6567              532          Umbrella                  9             Black   \n",
      "\n",
      "      predicted_units_sold  week_ahead       week  rebalance_flag  \n",
      "0                       44           1 2020-03-02           False  \n",
      "1                       56           1 2020-03-02           False  \n",
      "2                      401           1 2020-03-02           False  \n",
      "3                       80           1 2020-03-02           False  \n",
      "4                       40           1 2020-03-02           False  \n",
      "...                    ...         ...        ...             ...  \n",
      "6563                     4           4 2020-04-13           False  \n",
      "6564                     3           4 2020-04-13           False  \n",
      "6565                    21           4 2020-04-13           False  \n",
      "6566                    14           4 2020-04-13           False  \n",
      "6567                   114           4 2020-04-13           False  \n",
      "\n",
      "[6568 rows x 8 columns]\n",
      "\n",
      "Total Predicted Units for 4 Future Weeks: 913718\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# Initialize an empty DataFrame to store predictions for each future week\n",
    "future_predictions = pd.DataFrame()\n",
    "\n",
    "# Predict for 4 future weeks\n",
    "for week_ahead in range(1, 5):\n",
    "    # Prepare features for prediction using the last week's data\n",
    "    X_future = last_week_data[feature_columns]  # Ensure feature_columns include all necessary features\n",
    "    \n",
    "    # Step 1: Generate predictions from each base model for the current week\n",
    "    preds_rf = model_rf.predict(X_future)\n",
    "    preds_lr = model_lr.predict(X_future)\n",
    "    preds_mlp = model_mlp.predict(X_future)\n",
    "    \n",
    "    # Step 2: Create DataFrame with base model predictions to input to the meta-model\n",
    "    base_preds_df = pd.DataFrame({\n",
    "        'RandomForest': preds_rf,\n",
    "        'LinearRegression': preds_lr,\n",
    "        'MLPRegressor': preds_mlp\n",
    "    })\n",
    "    \n",
    "    # Step 3: Use the meta-model to predict the final units sold\n",
    "    future_pred = final_model_rf.predict(base_preds_df)\n",
    "    future_pred = np.round(future_pred).astype(int)  # Ensure integer values\n",
    "    \n",
    "    # Step 4: Create a DataFrame to store predictions\n",
    "    prediction_df = last_week_data[['product_type_no', 'product_type_name', \n",
    "                                    'colour_group_code', 'colour_group_name']].copy()\n",
    "    prediction_df['predicted_units_sold'] = future_pred\n",
    "    prediction_df['week_ahead'] = week_ahead  # Label the future week\n",
    "    \n",
    "    # Step 4b: Add a new 'week' column by advancing by 7 days for each iteration\n",
    "    if 'week' in last_week_data.columns:\n",
    "        prediction_df['week'] = last_week_data['week'] + timedelta(weeks=week_ahead)\n",
    "    else:\n",
    "        prediction_df['week'] = last_week_data['week'].max() + timedelta(weeks=week_ahead)\n",
    "\n",
    "    # Step 5: Calculate rolling 4-week cumulative demand\n",
    "    last_week_data['low_demand_4weeks'] = (\n",
    "        last_week_data['low_demand_4weeks'].shift(1).fillna(0) + future_pred\n",
    "    )\n",
    "    \n",
    "    # Step 6: Flag for rebalancing\n",
    "    prediction_df['rebalance_flag'] = np.where(\n",
    "        (last_week_data['is_peak_season'] & (last_week_data['low_demand_4weeks'] <= last_week_data['low_demand_threshold'])) |\n",
    "        (~last_week_data['is_peak_season'] & (last_week_data['low_demand_4weeks'] <= (last_week_data['low_demand_threshold'] * 1.5))),\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "    \n",
    "    # Append predictions to the future_predictions DataFrame\n",
    "    future_predictions = pd.concat([future_predictions, prediction_df], ignore_index=True)\n",
    "    \n",
    "    # Step 7: Update last_week_data for the next week's predictions\n",
    "    # Shift lagged features and update total_units_sold\n",
    "    last_week_data['lag_units_sold_2weeks'] = last_week_data['lag_units_sold_1week']\n",
    "    last_week_data['lag_units_sold_1week'] = future_pred\n",
    "    last_week_data['total_units_sold'] = future_pred\n",
    "    last_week_data['week'] = last_week_data['week'] + timedelta(weeks=1)  # Move to the next week\n",
    "\n",
    "# Display the resulting DataFrame with predictions and rebalancing flags for 4 future weeks\n",
    "print(\"\\nFuture Predictions with Rebalance Flags for 4 Weeks Out:\")\n",
    "print(future_predictions)\n",
    "\n",
    "# Calculate the total predicted units across all weeks\n",
    "total_predicted_units = future_predictions['predicted_units_sold'].sum()\n",
    "print(f\"\\nTotal Predicted Units for 4 Future Weeks: {total_predicted_units}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Future Predictions with Rebalance Flags for 4 Weeks Out:\n",
      "      product_type_no product_type_name  colour_group_code colour_group_name  \\\n",
      "0                  -1           Unknown                  6        Light Grey   \n",
      "1                  -1           Unknown                  7              Grey   \n",
      "2                  -1           Unknown                  9             Black   \n",
      "3                  -1           Unknown                 10             White   \n",
      "4                  -1           Unknown                 12       Light Beige   \n",
      "...               ...               ...                ...               ...   \n",
      "6563              515         Straw hat                 11         Off White   \n",
      "6564              525          Keychain                  3            Silver   \n",
      "6565              529       Mobile case                 31      Light Orange   \n",
      "6566              529       Mobile case                 52              Pink   \n",
      "6567              532          Umbrella                  9             Black   \n",
      "\n",
      "      predicted_units_sold  week_ahead  rebalance_flag  \n",
      "0                       44           1            True  \n",
      "1                       56           1            True  \n",
      "2                      401           1           False  \n",
      "3                       80           1           False  \n",
      "4                       40           1            True  \n",
      "...                    ...         ...             ...  \n",
      "6563                     4           4           False  \n",
      "6564                     3           4           False  \n",
      "6565                    21           4            True  \n",
      "6566                    14           4            True  \n",
      "6567                   114           4           False  \n",
      "\n",
      "[6568 rows x 7 columns]\n",
      "\n",
      "Total Predicted Units for 4 Future Weeks: 913718\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract the last week of February 2020\n",
    "data['week'] = pd.to_datetime(data['week']).dt.tz_localize(None)\n",
    "last_week_data = data[(data['week'] >= \"2020-02-24\") & (data['week'] <= \"2020-02-29\")].copy()\n",
    "\n",
    "# Step 2: Ensure all required columns are present\n",
    "# If lagged features and rolling columns are not in last_week_data, initialize them as needed\n",
    "if 'lag_units_sold_1week' not in last_week_data.columns:\n",
    "    last_week_data['lag_units_sold_1week'] = last_week_data['total_units_sold'].shift(1).fillna(0)\n",
    "if 'lag_units_sold_2weeks' not in last_week_data.columns:\n",
    "    last_week_data['lag_units_sold_2weeks'] = last_week_data['total_units_sold'].shift(2).fillna(0)\n",
    "if 'low_demand_4weeks' not in last_week_data.columns:\n",
    "    last_week_data['low_demand_4weeks'] = last_week_data['total_units_sold']  # Start with current units sold\n",
    "if 'is_peak_season' not in last_week_data.columns:\n",
    "    last_week_data['is_peak_season'] = False  # Assuming False if unknown\n",
    "if 'low_demand_threshold' not in last_week_data.columns:\n",
    "    last_week_data['low_demand_threshold'] = last_week_data['total_units_sold'].mean()  # Example threshold\n",
    "\n",
    "# Initialize an empty DataFrame to store predictions for each future week\n",
    "future_predictions = pd.DataFrame()\n",
    "\n",
    "# Step 3: Predict for 4 future weeks\n",
    "for week_ahead in range(1, 5):\n",
    "    # Prepare features for prediction using the last week's data\n",
    "    X_future = last_week_data[feature_columns]  # Ensure feature_columns include all necessary features\n",
    "    \n",
    "    # Step 1: Generate predictions from each base model for the current week\n",
    "    preds_rf = model_rf.predict(X_future)\n",
    "    preds_lr = model_lr.predict(X_future)\n",
    "    preds_mlp = model_mlp.predict(X_future)\n",
    "    \n",
    "    # Step 2: Create DataFrame with base model predictions to input to the meta-model\n",
    "    base_preds_df = pd.DataFrame({\n",
    "        'RandomForest': preds_rf,\n",
    "        'LinearRegression': preds_lr,\n",
    "        'MLPRegressor': preds_mlp\n",
    "    })\n",
    "    \n",
    "    # Step 3: Use the meta-model to predict the final units sold\n",
    "    future_pred = final_model_rf.predict(base_preds_df)\n",
    "    future_pred = np.round(future_pred).astype(int)  # Ensure integer values\n",
    "    \n",
    "    # Step 4: Create a DataFrame to store predictions for this week\n",
    "    prediction_df = last_week_data[['product_type_no', 'product_type_name', \n",
    "                                    'colour_group_code', 'colour_group_name']].copy()\n",
    "    prediction_df['predicted_units_sold'] = future_pred\n",
    "    prediction_df['week_ahead'] = week_ahead  # Label the future week\n",
    "    \n",
    "    # Step 5: Update the rolling 4-week cumulative demand\n",
    "    last_week_data['low_demand_4weeks'] = (\n",
    "        last_week_data['low_demand_4weeks'].shift(1).fillna(0) + future_pred\n",
    "    )\n",
    "    \n",
    "    # Step 6: Flag items for rebalancing based on the updated demand threshold\n",
    "    prediction_df['rebalance_flag'] = np.where(\n",
    "        (last_week_data['is_peak_season'] & (last_week_data['low_demand_4weeks'] <= last_week_data['low_demand_threshold'])) |\n",
    "        (~last_week_data['is_peak_season'] & (last_week_data['low_demand_4weeks'] <= (last_week_data['low_demand_threshold'] * 1.5))),\n",
    "        True,\n",
    "        False\n",
    "    )\n",
    "    \n",
    "    # Append predictions to the future_predictions DataFrame\n",
    "    future_predictions = pd.concat([future_predictions, prediction_df], ignore_index=True)\n",
    "    \n",
    "    # Step 7: Update last_week_data to simulate moving into the next week\n",
    "    # Shift lagged features to reflect the new week's demand\n",
    "    last_week_data['lag_units_sold_2weeks'] = last_week_data['lag_units_sold_1week']\n",
    "    last_week_data['lag_units_sold_1week'] = future_pred\n",
    "    last_week_data['total_units_sold'] = future_pred  # Update with predicted units for the new week\n",
    "\n",
    "# Step 8: Display the resulting DataFrame with predictions and rebalancing flags for 4 future weeks\n",
    "print(\"\\nFuture Predictions with Rebalance Flags for 4 Weeks Out:\")\n",
    "print(future_predictions)\n",
    "\n",
    "# Calculate the total predicted units across all weeks\n",
    "total_predicted_units = future_predictions['predicted_units_sold'].sum()\n",
    "print(f\"\\nTotal Predicted Units for 4 Future Weeks: {total_predicted_units}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table successfully pushed to the database!\n"
     ]
    }
   ],
   "source": [
    "# Set up the schema if needed and push inventory_needs to PostgreSQL\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'SET search_path TO {my_schema};'))\n",
    "    future_predictions.to_sql('future_predictions', con=engine, schema=my_schema, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Table successfully pushed to the database!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
